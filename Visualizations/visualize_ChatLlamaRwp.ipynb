{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5cc0e670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "def load_json(file_path):\n",
    "    \"\"\"Load and return a JSON object from a file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found -> {file_path}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON in file {file_path}: {e}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def update_json(data, key, value): # Modify/Add Data\n",
    "    data[key] = value\n",
    "    return data\n",
    "\n",
    "def save_json(file_path, data): # Save JSON Data\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c232725a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ARR_39': {'llama_choice': 'I_2', 'chat_choice': 'I_1', 'rwp_choice': 'I_1'}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates a chart with the interpretation selections of Chat GPT, Llama and the Rwp minimization\n",
    "#includes synthesis, interpretation info, balance score, Rwp, and likelihoods for each LLM\n",
    "\n",
    "def find_all_choices(json_file):\n",
    "    sample_choice = {}\n",
    "    if 1 == 1:\n",
    "        sample = \"ARR_39\"\n",
    "        llama_probs = []\n",
    "        chat_probs = []\n",
    "        rwp_vals = []\n",
    "        sample_choice[sample] = {}\n",
    "        for interpret, info in json_file[sample].items():\n",
    "            if interpret == \"Synth_Conditions\":\n",
    "                continue\n",
    "            try:\n",
    "                llama_score = info[\"unnormalized_posterior_llama\"]\n",
    "                chat_score = info[\"unnormalized_posterior\"]\n",
    "                rwp = info[\"rwp\"]\n",
    "                if all(isinstance(x, (int, float)) for x in [llama_score, chat_score, rwp]):\n",
    "                    llama_probs.append((interpret, llama_score))\n",
    "                    chat_probs.append((interpret, chat_score))\n",
    "                    rwp_vals.append((interpret, rwp))\n",
    "            except KeyError as e:\n",
    "                print(f\"Missing key in sample '{sample}', interpretation '{interpret}': {e}\")\n",
    "        \n",
    "        sample_choice[sample][\"llama_choice\"] = max(llama_probs, key=lambda x: x[1])[0] if llama_probs else None\n",
    "        sample_choice[sample][\"chat_choice\"] = max(chat_probs, key=lambda x: x[1])[0] if chat_probs else None\n",
    "        sample_choice[sample][\"rwp_choice\"] = min(rwp_vals, key=lambda x: x[1])[0] if rwp_vals else None\n",
    "    \n",
    "    return sample_choice\n",
    "file_path = \"/Users/admin/Documents/GitHub/LLM_XRD_Interpretation_Validation/Data/prompt3/interpretations_llm_v1_llama1.json\"\n",
    "json_file = load_json(file_path)\n",
    "find_all_choices(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "990f6886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Selection Method</th>\n",
       "      <th>Choice</th>\n",
       "      <th>Predicted Phases</th>\n",
       "      <th>Balance Score</th>\n",
       "      <th>Rwp</th>\n",
       "      <th>Chat GPT Likelihood</th>\n",
       "      <th>Llama Likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chat GPT</td>\n",
       "      <td>I_1</td>\n",
       "      <td>Ga33O50_12 100.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>20.11</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Llama</td>\n",
       "      <td>I_2</td>\n",
       "      <td>Ga2O3_12 100.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>20.14</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lowest Rwp</td>\n",
       "      <td>I_1</td>\n",
       "      <td>Ga33O50_12 100.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>20.11</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Selection Method Choice  Predicted Phases  Balance Score    Rwp  \\\n",
       "0         Chat GPT    I_1  Ga33O50_12 100.0          0.375  20.11   \n",
       "1            Llama    I_2    Ga2O3_12 100.0          0.375  20.14   \n",
       "2       Lowest Rwp    I_1  Ga33O50_12 100.0          0.375  20.11   \n",
       "\n",
       "   Chat GPT Likelihood  Llama Likelihood  \n",
       "0                 0.35              0.35  \n",
       "1                 0.35              0.35  \n",
       "2                 0.35              0.35  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = \"/Users/admin/Documents/GitHub/LLM_XRD_Interpretation_Validation/Data/prompt3/interpretations_llm_v1_llama1.json\"\n",
    "json_file = load_json(file_path)\n",
    "sample_id = 'ARR_39'  # sample name\n",
    "\n",
    "def format_predicted_phases(json_file, sample_id, chat_choice):\n",
    "    phases = json_file[sample_id][chat_choice][\"phases\"]\n",
    "    wfs = json_file[sample_id][chat_choice][\"weight_fraction\"]\n",
    "    phase_list = \"\"\n",
    "    for i in range(len(phases)):\n",
    "        if not phase_list:\n",
    "            phase_list += f\"{phases[i]} {wfs[i]}\"\n",
    "        else: phase_list += f\", {phases[i]} {wfs[i]}\"\n",
    "    return phase_list\n",
    "\n",
    "# Helper function to extract values safely\n",
    "def assemble_df(sample_id, sample_choice, json_file):\n",
    "    rows = []\n",
    "    # assign Chat GPT row values\n",
    "    chat_row = {}\n",
    "    chat_choice = sample_choice[sample_id][\"chat_choice\"]\n",
    "    chat_row[\"Selection Method\"] = \"Chat GPT\"\n",
    "    chat_row[\"Choice\"] = chat_choice\n",
    "    chat_row[\"Predicted Phases\"] = format_predicted_phases(json_file, sample_id, chat_choice)\n",
    "    chat_row[\"Balance Score\"] = json_file[sample_id][chat_choice][\"balance_score\"]\n",
    "    chat_row[\"Rwp\"] = json_file[sample_id][chat_choice][\"rwp\"]\n",
    "    chat_row[\"Chat GPT Likelihood\"] = json_file[sample_id][chat_choice][\"LLM_interpretation_likelihood\"]\n",
    "    chat_row[\"Llama Likelihood\"] = json_file[sample_id][chat_choice][\"LLM_interpretation_likelihood\"]\n",
    "\n",
    "    #assign Llama row values\n",
    "    llama_row = {}\n",
    "    llama_choice = sample_choice[sample_id][\"llama_choice\"]\n",
    "    llama_row[\"Selection Method\"] = \"Llama\"\n",
    "    llama_row[\"Choice\"] = llama_choice\n",
    "    llama_row[\"Predicted Phases\"] = format_predicted_phases(json_file, sample_id, llama_choice)\n",
    "    llama_row[\"Balance Score\"] = json_file[sample_id][llama_choice][\"balance_score\"]\n",
    "    llama_row[\"Rwp\"] = json_file[sample_id][llama_choice][\"rwp\"]\n",
    "    llama_row[\"Chat GPT Likelihood\"] = json_file[sample_id][llama_choice][\"LLM_interpretation_likelihood\"]\n",
    "    llama_row[\"Llama Likelihood\"] = json_file[sample_id][llama_choice][\"LLM_interpretation_likelihood\"]\n",
    "\n",
    "    #assign lowest Rwp values\n",
    "    rwp_row = {}\n",
    "    rwp_choice = sample_choice[sample_id][\"rwp_choice\"]\n",
    "    rwp_row[\"Selection Method\"] = \"Lowest Rwp\"\n",
    "    rwp_row[\"Choice\"] = rwp_choice\n",
    "    rwp_row[\"Predicted Phases\"] = format_predicted_phases(json_file, sample_id, rwp_choice)\n",
    "    rwp_row[\"Balance Score\"] = json_file[sample_id][rwp_choice][\"balance_score\"]\n",
    "    rwp_row[\"Rwp\"] = json_file[sample_id][rwp_choice][\"rwp\"]\n",
    "    rwp_row[\"Chat GPT Likelihood\"] = json_file[sample_id][rwp_choice][\"LLM_interpretation_likelihood\"]\n",
    "    rwp_row[\"Llama Likelihood\"] = json_file[sample_id][rwp_choice][\"LLM_interpretation_likelihood\"]\n",
    "    rows = [chat_row, llama_row, rwp_row]\n",
    "    return rows\n",
    "\n",
    "sample_choice = find_all_choices(json_file)\n",
    "rows = assemble_df(sample_id, sample_choice, json_file)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "df = df[[\"Selection Method\", \"Choice\", \"Predicted Phases\", \"Balance Score\", \"Rwp\", \"Chat GPT Likelihood\", \"Llama Likelihood\"]]\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c23e212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
