{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps to follow in order to get the selected interpration by using LLama:\n",
    "1. run all data train and test with the new prompt with llama\n",
    "2. interpretations = calculate_prior_probability(interpretations, w_llm=0.5, w_bscore =0.7)\n",
    "3. interpretations = calculate_fit_quality(interpretations,w_rwp=1, w_score=0.5)\n",
    "4. interpretations = calculate_posterior_probability_of_interpretation(interpretations)\n",
    "\n",
    "\n",
    "Make sure LLM_interpretation_likelihood is updated with the LLama's answer & you store the final prior and fit_quality and posterior with different name, do not overwrite the excisting one. Then we can compare the selected interpretation(higher prob) by using Chatgpt vs LLama vs \"lowset rwp valus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_prior_probability(interpretations, w_llm=1, w_bscore=1):\n",
    "    # Update each interpretation with a new field \"prior_probability\"\n",
    "    for interpretation_name, interpretation in interpretations.items():\n",
    "        interpretation[\"prior_probability_llama\"] = (\n",
    "           (interpretation[\"LLM_interpretation_likelihood_llama\"]*w_llm + interpretation[\"balance_score\"]*w_bscore)/(w_llm + w_bscore)\n",
    "        )\n",
    "    return interpretations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fit_quality(interpretations, w_rwp=1, w_score=1):\n",
    "    for key, interpretation in interpretations.items():\n",
    "        interpretation[\"fit_quality\"] = (interpretation[\"normalized_rwp\"]*w_rwp + interpretation[\"normalized_score\"]*w_score) / (w_rwp + w_score)\n",
    "    return interpretations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_posterior_probability_of_interpretation(interpretations):\n",
    "    \"\"\"\n",
    "    Calculate the posterior probabilities P(In | S) for all interpretations\n",
    "    using balance_score and interpretation_importance.\n",
    "    \n",
    "    Parameters:\n",
    "        interpretations (dict or list): A dictionary of interpretations or \n",
    "                                        a list containing a single dictionary.\n",
    "\n",
    "    Returns:\n",
    "        dict: Updated interpretations with added \"posterior_probability\" field.\n",
    "    \"\"\"\n",
    "    # Extract dictionary if interpretations is a list\n",
    "    if isinstance(interpretations, list) and len(interpretations) == 1:\n",
    "        interpretations = interpretations[0]  # Extract the dictionary\n",
    "\n",
    "    if not isinstance(interpretations, dict):\n",
    "        raise ValueError(\"Interpretations should be a dictionary or a list containing a dictionary.\")\n",
    "\n",
    "     # Step 1: Compute unnormalized posterior = prior * fit_quality\n",
    "    joint_probabilities = {}\n",
    "    for name, interp in interpretations.items():\n",
    "        joint = interp[\"prior_probability\"] * interp[\"fit_quality\"]\n",
    "        interpretations[name][\"unnormalized_posterior\"] = joint\n",
    "        joint_probabilities[name] = joint\n",
    "\n",
    "    # Step 2: Normalize to get posterior_probability\n",
    "    total_joint = sum(joint_probabilities.values())\n",
    "    for name in interpretations:\n",
    "        if total_joint > 0:\n",
    "            interpretations[name][\"posterior_probability\"] = (\n",
    "                interpretations[name][\"unnormalized_posterior\"] / total_joint\n",
    "            )\n",
    "        else:\n",
    "            interpretations[name][\"posterior_probability\"] = 0.0\n",
    "\n",
    "    return interpretations  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
